---
layout : post
title: Elmo
author: Hojoon_Kim
date: 2024-01-24 15:15:10 +0900
categories: [Develope, NLP]
tags: [DL, NLP, Elmo]
pin: true
math: true
---
ELmo(Embedding from Language Model)는 2018년에 제안된 새로운 사전 훈련된 언어 모델이다. 기존의 임베딩 벡터들은 동음이의어( Bank Account, River Bank 들의 Bank) 와 같은 것들을 구분하지 못한다는 단점이 있었다. 이러한 단점을 보완하기 위해 제안된 것이 ELmo이다. ELmo는 언어 모델을 통해 단어의 의미를 표현하는 벡터를 만들어 낸다. 이러한 벡터는 단어의 의미를 표현할 수 있기 때문에 동음이의어를 구분할 수 있다. 또한, ELmo는 단어의 의미를 표현하는 벡터를 만들어 내기 때문에, 기존의 임베딩 벡터들과는 달리 단어의 위치에 따라서 단어의 의미가 달라지는 것을 반영할 수 있다. 이러한 특징을 가지고 있기 때문에 ELmo는 기존의 임베딩 벡터들보다 더욱 정확한 자연어 처리를 할 수 있다.

## biLM(Bidirectional Language Model)의 사전 훈련
RNN 언어 모델은 문장을 받을 때 단어 단위로 입력을 받는데, 이때 입력을 받는 방향에 따라서 다음과 같이 두 가지로 나눌 수 있다. 첫 번째는 앞에서부터 단어를 입력 받는 방향인 Forward Language Model이고, 두 번째는 뒤에서부터 단어를 입력 받는 방향인 Backward Language Model이다. 이 두 가지 방향으로 언어 모델을 훈련시킨 것을 biLM이라고 한다. biLM은 양방향으로 언어 모델을 훈련시키기 때문에, 단어의 의미를 표현하는 벡터를 만들어 낼 수 있다. 이러한 biLM을 통해 단어의 의미를 표현하는 벡터를 만들어 내는 것이 ELmo이다. 이 때 벡터를 얻는 것은 임베딩 층을 통해서 얻는 것이 아니라 합성곱 신경망을 이용해서 얻는다. 합성곱 신경망을 이용해서 얻는 것은 단어의 위치에 따라서 단어의 의미가 달라지는 것을 반영할 수 있기 때문이다.

## biLM의 임베딩 과정
1. 각 층(순방향, 역방향)의 출력값을 연결한다.
2. 연결된 출력값을 각층의 출력값 별로 가중치를 둔다.
3. 가중치를 둔 값들을 모두 더한다.
4. 벡터의 크기를 결정하는 스칼라 매개변수를 곱한다.
