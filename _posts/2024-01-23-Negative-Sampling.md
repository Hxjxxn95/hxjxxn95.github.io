---
layout : post
title: Negative Sampling
author: Hojoon_Kim
date: 2024-01-23 14:15:10 +0900
categories: [Develope, NLP]
tags: [DL, NLP, NegativeSampling]
pin: true
math: true
---
만약 단어가 10000개가 있다고 하자. 이때 단어를 원-핫 인코딩으로 표현하면 10000차원의 벡터가 된다. 이런 고차원의 벡터를 다루는 것은 계산 비용이 많이 든다. 이를 해결하기 위해 사용하는 방법이 Negative Sampling 이다. Negative Sampling 은 Word2Vec 의 학습 속도를 개선하는 방법이다.
네거티브 샘플링은 주변 단어들을 예측하는 것이 아니라, 주변 단어들과 무작위로 선택된 K개의 단어들을 구분하는 이진 분류 문제로 바꾸는 것이다. 이때 K는 5~20 사이의 값을 가진다. K개의 단어들을 네거티브 샘플이라고 한다.

## 네거티브 샘플링 Skip-gram
네거티브 샘플링 Skip-gram 은 중심 단어와 주변 단어를 예측하는 것이 아니라, 중심 단어와 랜덤으로 선택된 K개의 단어들이 주어졌을 때, 이 단어들이 중심 단어와 관련이 있는지를 예측하는 문제로 바꾸는 것이다. 이때 중심 단어와 관련이 있다면 1, 관련이 없다면 0으로 레이블링한다. 이때 중심 단어와 관련이 있는 단어들은 긍정적인 예(Positive Example), 관련이 없는 단어들은 부정적인 예(Negative Example)라고 한다. 이진 분류 문제이기 때문에 시그모이드 함수를 사용한다. 이때 시그모이드 함수의 입력값은 중심 단어와 주변 단어의 내적이다. 이때 내적값이 0에 가까우면 0에 가까운 값이 나오고, 내적값이 1에 가까우면 1에 가까운 값이 나온다. 이때 내적값이 1에 가까워지는 것은 중심 단어와 주변 단어가 관련이 있다는 것을 의미한다.

## Reference
[위키독스 - 딥 러닝을 이용한 자연어 처리 입문](https://wikidocs.net/book/2155)